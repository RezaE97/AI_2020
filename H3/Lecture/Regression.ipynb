{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "A3b72Tggdr1o",
        "colab_type": "text"
      },
      "source": [
        "<h1><center>Simple Linear Regression</center></h1>\n",
        "\n",
        "\n",
        "<h4>About this Notebook</h4>\n",
        "In this notebook, we learn how to use scikit-learn to implement simple linear regression, multiple linear regression and polynomial regression. We download a dataset that is related to fuel consumption and Carbon dioxide emission of cars. Then, we split our data into training and test sets, create a model using training set, evaluate your model using test set, and finally use model to predict unknown value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "TrCxJbUTdr1y",
        "colab_type": "text"
      },
      "source": [
        "### Importing Needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "E4WT1nn2dr12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "c67DzvFIdr3Q",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h2 id=\"understanding_data\">Understanding the Data</h2>\n",
        "\n",
        "### `FuelConsumption.csv`:\n",
        "We have downloaded a fuel consumption dataset, **`FuelConsumption.csv`**, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. [Dataset source](http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)\n",
        "\n",
        "- **MODELYEAR** e.g. 2014\n",
        "- **MAKE** e.g. Acura\n",
        "- **MODEL** e.g. ILX\n",
        "- **VEHICLE CLASS** e.g. SUV\n",
        "- **ENGINE SIZE** e.g. 4.7\n",
        "- **CYLINDERS** e.g 6\n",
        "- **TRANSMISSION** e.g. A6\n",
        "- **FUEL CONSUMPTION in CITY(L/100 km)** e.g. 9.9\n",
        "- **FUEL CONSUMPTION in HWY (L/100 km)** e.g. 8.9\n",
        "- **FUEL CONSUMPTION COMB (L/100 km)** e.g. 9.2\n",
        "- **CO2 EMISSIONS (g/km)** e.g. 182   --> low --> 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "nOPUhVY-dr3U",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"reading_data\">Reading the data in</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "EBuehqyodr3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"FuelConsumption.csv\")\n",
        "\n",
        "# take a look at the dataset\n",
        "df.head()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0W-HNZ9-FjU",
        "colab_type": "text"
      },
      "source": [
        "Note that if your data are in excell formats, it is still possible to load data with pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2GAII9y-QW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=pd.read_excel(\"cancer.xlsx\")\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "McMOy5xRdr3m",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"data_exploration\">Data Exploration</h2>\n",
        "Lets first have a descriptive exploration on our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "l2dmlg04dr3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize the data\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLxh4WHLdr32",
        "colab_type": "text"
      },
      "source": [
        "Lets select some features to explore more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "pOlfoxwpdr34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cdf = df[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']]\n",
        "cdf.head(9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjowwONqdr4C",
        "colab_type": "text"
      },
      "source": [
        "we can plot each of these features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "EOwOkLgDdr4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "viz = cdf[['CYLINDERS','ENGINESIZE','CO2EMISSIONS','FUELCONSUMPTION_COMB']]\n",
        "viz.hist()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4IPlBgQdr4M",
        "colab_type": "text"
      },
      "source": [
        "Now, lets plot each of these features vs the Emission, to see how linear is their relation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Kjwx-YjEdr4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(cdf.FUELCONSUMPTION_COMB, cdf.CO2EMISSIONS,  color='blue')\n",
        "plt.xlabel(\"FUELCONSUMPTION_COMB\")\n",
        "plt.ylabel(\"Emission\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "id": "YYguLWd-dr4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(cdf.ENGINESIZE, cdf.CO2EMISSIONS,  color='blue')\n",
        "plt.xlabel(\"Engine size\")\n",
        "plt.ylabel(\"Emission\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "RDZTW7fddr41",
        "colab_type": "text"
      },
      "source": [
        "#### Creating train and test dataset\n",
        "Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. \n",
        "This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems.\n",
        "\n",
        "This means that we know the outcome of each data point in this dataset, making it great to test with! And since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, it is truly an out-of-sample testing.\n",
        "\n",
        "Lets split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. We create a mask to select random rows using __np.random.rand()__ function: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "TAwZ3X0Hdr43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "msk = np.random.rand(len(df)) < 0.8\n",
        "train = cdf[msk]\n",
        "test = cdf[~msk]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "asLl4GASdr4-",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"simple_regression\">Simple Regression Model</h2>\n",
        "Linear Regression fits a linear model with coefficients $W = (W_1, ..., W_n)$ to minimize the 'residual sum of squares' between the independent x in the dataset, and the dependent y by the linear approximation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "F_k_c5EXdr4_",
        "colab_type": "text"
      },
      "source": [
        "#### Train data distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "KZWTLJ5Cdr5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')\n",
        "plt.xlabel(\"Engine size\")\n",
        "plt.ylabel(\"Emission\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "UWr__CZsdr5D",
        "colab_type": "text"
      },
      "source": [
        "#### Modeling\n",
        "Using sklearn package to model data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "y73-Dyrudr5E",
        "colab_type": "code",
        "outputId": "7bcf0695-4953-4600-d9fa-40fd3396b868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "regr = linear_model.LinearRegression()\n",
        "train_x = np.array(train[['ENGINESIZE']])\n",
        "train_y = np.array(train[['CO2EMISSIONS']])\n",
        "regr.fit (train_x, train_y)\n",
        "# The coefficients\n",
        "print ('Coefficients: ', regr.coef_)\n",
        "print ('Intercept: ',regr.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients:  [[39.73791459]]\n",
            "Intercept:  [123.48245052]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yvsCP9zdr5N",
        "colab_type": "text"
      },
      "source": [
        "As mentioned before, __Coefficient__ and __Intercept__ in the simple linear regression, are the parameters of the fit line. \n",
        "Given that it is a simple linear regression, with only 2 parameters, and knowing that the parameters are the intercept and slope of the line, sklearn can estimate them directly from our data. \n",
        "Notice that all of the data must be available to traverse and calculate the parameters.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Ie2Dgq5Bdr5O",
        "colab_type": "text"
      },
      "source": [
        "#### Plot outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhCUzir8dr5P",
        "colab_type": "text"
      },
      "source": [
        "we can plot the fit line over the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "NlgZt7e_dr5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')\n",
        "plt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\n",
        "plt.xlabel(\"Engine size\")\n",
        "plt.ylabel(\"Emission\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "89jLLy0ldr5X",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluation\n",
        "we compare the actual values and predicted values to calculate the accuracy of a regression model. Evaluation metrics provide a key role in the development of a model, as it provides insight to areas that require improvement.\n",
        "\n",
        "There are different model evaluation metrics, lets use MSE here to calculate the accuracy of our model based on the test set: \n",
        "<ul>\n",
        "    <li> Mean absolute error: It is the mean of the absolute value of the errors. This is the easiest of the metrics to understand since it’s just average error.</li>\n",
        "    <li> Mean Squared Error (MSE): Mean Squared Error (MSE) is the mean of the squared error. It’s more popular than Mean absolute error because the focus is geared more towards large errors. This is due to the squared term exponentially increasing larger errors in comparison to smaller ones.</li>\n",
        "    <li> Root Mean Squared Error (RMSE): This is the square root of the Mean Square Error. </li>\n",
        "    <li> R-squared is not error, but is a popular metric for accuracy of your model. It represents how close the data are to the fitted regression line. The higher the R-squared, the better the model fits your data. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "deletable": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "scrolled": true,
        "id": "k4G29xxwdr5X",
        "colab_type": "code",
        "outputId": "11991d1c-893b-4908-c9f9-cec239e40199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "test_x = np.array(test[['ENGINESIZE']])\n",
        "test_y = np.array(test[['CO2EMISSIONS']])\n",
        "test_y_hat = regr.predict(test_x)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_hat - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_hat - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y_hat , test_y) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean absolute error: 24.00\n",
            "Residual sum of squares (MSE): 990.01\n",
            "R2-score: 0.70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZ93_XSsaiv",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"multiple_regression_model\">K-fold Cross Validation</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTRyufW-slia",
        "colab_type": "text"
      },
      "source": [
        "A solution to over-fitting problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the k “folds”:\n",
        "\n",
        "A model is trained using  of the folds as training data;\n",
        "\n",
        "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy).\n",
        "\n",
        "The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small.\n",
        "![alt text](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjggotkF7Z_i",
        "colab_type": "text"
      },
      "source": [
        "Now, let's have a look at how k-fold splits the dataset into sub-sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJNmOdZ07rOE",
        "colab_type": "code",
        "outputId": "3aa33801-31c1-4016-f6a6-7f70cd2ec720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        " from sklearn.model_selection import KFold\n",
        " X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
        " y = np.array([1, 2, 3, 4])\n",
        " kf = KFold(n_splits=2)\n",
        " train,test=kf.split(X)\n",
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([2, 3]), array([0, 1]))\n",
            "(array([0, 1]), array([2, 3]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_iKCFJD8c_8",
        "colab_type": "text"
      },
      "source": [
        "Now let's come back to our example and train a linear model and evaluate it by r2 score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIWparAg1AEJ",
        "colab_type": "code",
        "outputId": "0194ef74-6778-41e7-c4f1-d6d4f35eb407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "regr = linear_model.LinearRegression()\n",
        "x = np.array(cdf[['ENGINESIZE']])\n",
        "y = np.array(cdf[['CO2EMISSIONS']])\n",
        "scores = cross_val_score(regr, x, y, cv=5, scoring=\"r2\")\n",
        "print(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.74334613 0.7838278  0.72801992 0.73032948 0.78636053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8baAxMSjSMPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "predictor=sklearn.model_selection.cross_val_predict(regr, x, y, cv=5)\n",
        "sklearn.model_selection.cross_val_predict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydSnMMlo84Mn",
        "colab_type": "text"
      },
      "source": [
        "We can also use mutiple evaluation metrics at the same time. Note that we need to import cross_validate instead of cross_val_score. you can find more scoring parameters <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">here</a>.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6elOYEU95m6K",
        "colab_type": "code",
        "outputId": "d4fa3e7b-ffe9-4bb7-d349-c31fed396fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "regr = linear_model.LinearRegression()\n",
        "scores=['neg_mean_squared_error','r2']\n",
        "scores = cross_validate(regr, x, y, cv=5, scoring=scores,return_estimator=True)\n",
        "print(scores)\n",
        "print(scores['test_r2'])\n",
        "print(scores['test_neg_mean_squared_error'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.74334613 0.7838278  0.72801992 0.73032948 0.78636053]\n",
            "[ -880.01976439 -1055.03715804 -1075.61966982 -1023.27423464\n",
            "  -747.38339934]\n",
            "{'fit_time': array([0.00123405, 0.0007031 , 0.00058508, 0.00082302, 0.00045061]), 'score_time': array([0.00181055, 0.00102806, 0.00092697, 0.00075459, 0.00058627]), 'estimator': (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)), 'test_neg_mean_squared_error': array([ -880.01976439, -1055.03715804, -1075.61966982, -1023.27423464,\n",
            "        -747.38339934]), 'test_r2': array([0.74334613, 0.7838278 , 0.72801992, 0.73032948, 0.78636053])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyLadm9Bf0KS",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"multiple_regression_model\">Multiple Regression Model</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5jwWIhQf4Be",
        "colab_type": "text"
      },
      "source": [
        "In reality, there are multiple variables that predict the Co2emission. When more than one independent variable is present, the process is called multiple linear regression. For example, predicting co2emission using FUELCONSUMPTION_COMB, EngineSize and Cylinders of cars. The good thing here is that Multiple linear regression is the extension of simple linear regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXHSSrhYf1Tv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regr = linear_model.LinearRegression()\n",
        "x = np.array(train[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
        "y = np.array(train[['CO2EMISSIONS']])\n",
        "regr.fit (x, y)\n",
        "# The coefficients\n",
        "print ('Coefficients: ', regr.coef_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V_IKvAwgFn8",
        "colab_type": "text"
      },
      "source": [
        "As mentioned before, __Coefficient__ and __Intercept__ , are the parameters of the fit line. \n",
        "Given that it is a multiple linear regression, with 3 parameters, and knowing that the parameters are the intercept and coefficients of hyperplane, sklearn can estimate them from our data. Scikit-learn uses plain Ordinary Least Squares method to solve this problem.\n",
        "\n",
        "#### Ordinary Least Squares (OLS)\n",
        "OLS is a method for estimating the unknown parameters in a linear regression model. OLS chooses the parameters of a linear function of a set of explanatory variables by minimizing the sum of the squares of the differences between the target dependent variable and those predicted by the linear function. In other words, it tries to minimizes the sum of squared errors (SSE) or mean squared error (MSE) between the target variable (y) and our predicted output ($\\hat{y}$) over all samples in the dataset.\n",
        "\n",
        "OLS can find the best parameters using of the following methods:\n",
        "    - Solving the model parameters analytically using closed-form equations\n",
        "    - Using an optimization algorithm (Gradient Descent, Stochastic Gradient Descent, Newton’s Method, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKWZ20f1gPh9",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"prediction\">Prediction</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btx20_KpgTjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_hat= regr.predict(test[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
        "x = np.asanyarray(test[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB']])\n",
        "y = np.asanyarray(test[['CO2EMISSIONS']])\n",
        "print(\"Residual sum of squares: %.2f\"\n",
        "      % np.mean((y_hat - y) ** 2))\n",
        "\n",
        "# Explained variance score: 1 is perfect prediction\n",
        "print('Variance score: %.2f' % regr.score(x, y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrYvoVjzgQqc",
        "colab_type": "text"
      },
      "source": [
        "__explained variance regression score:__  \n",
        "If $\\hat{y}$ is the estimated target output, y the corresponding (correct) target output, and Var is Variance, the square of the standard deviation, then the explained variance is estimated as follow:\n",
        "\n",
        "$\\texttt{explainedVariance}(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$  \n",
        "The best possible score is 1.0, lower values are worse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI5vu5kMhXID",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"polynomial_regression\">Polynomial regression</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQTvyhv8hYXh",
        "colab_type": "text"
      },
      "source": [
        "Sometimes, the trend of data is not really linear, and looks curvy. In this case we can use Polynomial regression methods. In fact, many different regressions exist that can be used to fit whatever the dataset looks like, such as quadratic, cubic, and so on, and it can go on and on to infinite degrees.\n",
        "\n",
        "In essence, we can call all of these, polynomial regression, where the relationship between the independent variable x and the dependent variable y is modeled as an nth degree polynomial in x. Lets say you want to have a polynomial regression (let's make 2 degree polynomial):\n",
        "\n",
        "\n",
        "$y = w_0 + w_1  x + w_2 x^2$\n",
        "\n",
        "Now, the question is: how we can fit our data on this equation while we have only x values, such as __Engine Size__? \n",
        "Well, we can create a few additional features: 1, $x$, and $x^2$.\n",
        "\n",
        "\n",
        "\n",
        "__PloynomialFeatures()__ function in Scikit-learn library, drives a new feature sets from the original feature set. That is, a matrix will be generated consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, lets say the original feature set has only one feature, _ENGINESIZE_. Now, if we select the degree of the polynomial to be 2, then it generates 3 features, degree=0, degree=1 and degree=2: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHlNMFSQhmgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "train_x = np.array(train[['ENGINESIZE']])\n",
        "train_y = np.array(train[['CO2EMISSIONS']])\n",
        "\n",
        "test_x = np.array(test[['ENGINESIZE']])\n",
        "test_y = np.array(test[['CO2EMISSIONS']])\n",
        "\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "train_x_poly = poly.fit_transform(train_x)\n",
        "train_x_poly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQWCELYJhsg1",
        "colab_type": "text"
      },
      "source": [
        "**fit_transform** takes our x values, and output a list of our data raised from power of 0 to power of 2 (since we set the degree of our polynomial to 2).\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    v_1\\\\\n",
        "    v_2\\\\\n",
        "    \\vdots\\\\\n",
        "    v_n\n",
        "\\end{bmatrix}\n",
        "$\n",
        "$\\longrightarrow$\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    [ 1 & v_1 & v_1^2]\\\\\n",
        "    [ 1 & v_2 & v_2^2]\\\\\n",
        "    \\vdots & \\vdots & \\vdots\\\\\n",
        "    [ 1 & v_n & v_n^2]\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "in our example\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    2.\\\\\n",
        "    2.4\\\\\n",
        "    1.5\\\\\n",
        "    \\vdots\n",
        "\\end{bmatrix}\n",
        "$\n",
        "$\\longrightarrow$\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    [ 1 & 2. & 4.]\\\\\n",
        "    [ 1 & 2.4 & 5.76]\\\\\n",
        "    [ 1 & 1.5 & 2.25]\\\\\n",
        "    \\vdots & \\vdots & \\vdots\\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j21k3rSmhx_o",
        "colab_type": "text"
      },
      "source": [
        "It looks like feature sets for multiple linear regression analysis, right? Yes. It Does. \n",
        "Indeed, Polynomial regression is a special case of linear regression, with the main idea of how do you select your features. Just consider replacing the  $x$ with $x_1$, $x_1^2$ with $x_2$, and so on. Then the degree 2 equation would be turn into:\n",
        "\n",
        "$y = w_0 + w_1  x_1 + w_2 x_2$\n",
        "\n",
        "Now, we can deal with it as 'linear regression' problem. Therefore, this polynomial regression is considered to be a special case of traditional multiple linear regression. So, you can use the same mechanism as linear regression to solve such a problems. \n",
        "\n",
        "\n",
        "\n",
        "so we can use __LinearRegression()__ function to solve it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVlEHWPbh4pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = linear_model.LinearRegression()\n",
        "train_y_ = clf.fit(train_x_poly, train_y)\n",
        "# The coefficients\n",
        "print ('Coefficients: ', clf.coef_)\n",
        "print ('Intercept: ',clf.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeLxCaZ4iHAi",
        "colab_type": "text"
      },
      "source": [
        "As mentioned before, __Coefficient__ and __Intercept__ , are the parameters of the fit curvy line. \n",
        "Given that it is a typical multiple linear regression, with 3 parameters, and knowing that the parameters are the intercept and coefficients of hyperplane, sklearn has estimated them from our new set of feature sets. Lets plot it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLi_19-GiN1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')\n",
        "XX = np.arange(0.0, 10.0, 0.1)\n",
        "yy = clf.intercept_[0]+ clf.coef_[0][1]*XX+ clf.coef_[0][2]*np.power(XX, 2)\n",
        "plt.plot(XX, yy, '-r' )\n",
        "plt.xlabel(\"Engine size\")\n",
        "plt.ylabel(\"Emission\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUNdhnhwiQne",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"evaluation\">Evaluation</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbrUoVKiVrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "test_x_poly = poly.fit_transform(test_x)\n",
        "test_y_ = clf.predict(test_x_poly)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y_ , test_y) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "deletable": true,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "FKytXH_Hdr5f",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h4>Author:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a></h4>\n",
        "\n",
        "\n",
        "<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
      ]
    }
  ]
}